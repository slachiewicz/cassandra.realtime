Spark Executor Command: "/home/gitpod/.sdkman/candidates/java/current/bin/java" "-cp" "/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/conf/:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/jars/*" "-Xmx1024M" "-Dspark.driver.port=37921" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921" "--executor-id" "0" "--hostname" "10.8.4.68" "--cores" "5" "--app-id" "app-20201116153043-0013" "--worker-url" "spark://Worker@10.8.4.68:43873"
========================================

Picked up JAVA_TOOL_OPTIONS: -Xmx2254m
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
20/11/16 15:30:44 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 24349@ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64
20/11/16 15:30:44 INFO SignalUtils: Registered signal handler for TERM
20/11/16 15:30:44 INFO SignalUtils: Registered signal handler for HUP
20/11/16 15:30:44 INFO SignalUtils: Registered signal handler for INT
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
20/11/16 15:30:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/11/16 15:30:45 INFO SecurityManager: Changing view acls to: gitpod
20/11/16 15:30:45 INFO SecurityManager: Changing modify acls to: gitpod
20/11/16 15:30:45 INFO SecurityManager: Changing view acls groups to: 
20/11/16 15:30:45 INFO SecurityManager: Changing modify acls groups to: 
20/11/16 15:30:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(gitpod); groups with view permissions: Set(); users  with modify permissions: Set(gitpod); groups with modify permissions: Set()
20/11/16 15:30:46 INFO TransportClientFactory: Successfully created connection to ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64/10.8.4.68:37921 after 105 ms (0 ms spent in bootstraps)
20/11/16 15:30:46 INFO SecurityManager: Changing view acls to: gitpod
20/11/16 15:30:46 INFO SecurityManager: Changing modify acls to: gitpod
20/11/16 15:30:46 INFO SecurityManager: Changing view acls groups to: 
20/11/16 15:30:46 INFO SecurityManager: Changing modify acls groups to: 
20/11/16 15:30:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(gitpod); groups with view permissions: Set(); users  with modify permissions: Set(gitpod); groups with modify permissions: Set()
20/11/16 15:30:46 INFO TransportClientFactory: Successfully created connection to ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64/10.8.4.68:37921 after 3 ms (0 ms spent in bootstraps)
20/11/16 15:30:46 INFO DiskBlockManager: Created local directory at /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/blockmgr-5b1d077d-6263-41f6-98c2-94c6db420b44
20/11/16 15:30:46 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
20/11/16 15:30:47 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921
20/11/16 15:30:47 INFO WorkerWatcher: Connecting to worker spark://Worker@10.8.4.68:43873
20/11/16 15:30:47 INFO TransportClientFactory: Successfully created connection to /10.8.4.68:43873 after 21 ms (0 ms spent in bootstraps)
20/11/16 15:30:47 INFO WorkerWatcher: Successfully connected to spark://Worker@10.8.4.68:43873
20/11/16 15:30:47 INFO ResourceUtils: ==============================================================
20/11/16 15:30:47 INFO ResourceUtils: Resources for spark.executor:

20/11/16 15:30:47 INFO ResourceUtils: ==============================================================
20/11/16 15:30:47 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
20/11/16 15:30:47 INFO Executor: Starting executor ID 0 on host 10.8.4.68
20/11/16 15:30:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41253.
20/11/16 15:30:47 INFO NettyBlockTransferService: Server created on 10.8.4.68:41253
20/11/16 15:30:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/11/16 15:30:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 10.8.4.68, 41253, None)
20/11/16 15:30:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 10.8.4.68, 41253, None)
20/11/16 15:30:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 10.8.4.68, 41253, None)
20/11/16 15:30:57 INFO CoarseGrainedExecutorBackend: Got assigned task 0
20/11/16 15:30:57 INFO CoarseGrainedExecutorBackend: Got assigned task 1
20/11/16 15:30:57 INFO CoarseGrainedExecutorBackend: Got assigned task 2
20/11/16 15:30:57 INFO CoarseGrainedExecutorBackend: Got assigned task 3
20/11/16 15:30:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
20/11/16 15:30:57 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
20/11/16 15:30:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/11/16 15:30:57 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
20/11/16 15:30:57 INFO CoarseGrainedExecutorBackend: Got assigned task 4
20/11/16 15:30:57 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/files/secure-connect-demo.zip with timestamp 1605540642976
20/11/16 15:30:57 INFO TransportClientFactory: Successfully created connection to ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64/10.8.4.68:37921 after 8 ms (0 ms spent in bootstraps)
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/files/secure-connect-demo.zip to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp16440157610723003701.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-11956286361605540642976_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./secure-connect-demo.zip
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1605540642975
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp6677812239531964113.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/18627995111605540642975_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.github.spotbugs_spotbugs-annotations-3.1.12.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.github.spotbugs_spotbugs-annotations-3.1.12.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.javatuples_javatuples-1.2.jar with timestamp 1605540642974
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.javatuples_javatuples-1.2.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp16863913042408971986.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-11928558021605540642974_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.javatuples_javatuples-1.2.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.javatuples_javatuples-1.2.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.oss_native-protocol-1.4.10.jar with timestamp 1605540642974
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.oss_native-protocol-1.4.10.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp5665428622859598843.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-17573173311605540642974_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.oss_native-protocol-1.4.10.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.oss_native-protocol-1.4.10.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1605540642975
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp16189799325036310610.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-15507114331605540642975_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.reactivestreams_reactive-streams-1.0.2.jar with timestamp 1605540642975
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.reactivestreams_reactive-streams-1.0.2.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp9384429855779639029.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-3189933991605540642975_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.reactivestreams_reactive-streams-1.0.2.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.reactivestreams_reactive-streams-1.0.2.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1605540642973
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp1640830857542465183.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/9769804391605540642973_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.thoughtworks.paranamer_paranamer-2.8.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.thoughtworks.paranamer_paranamer-2.8.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.oss_java-driver-query-builder-4.7.2.jar with timestamp 1605540642975
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.oss_java-driver-query-builder-4.7.2.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp16055635035578046254.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/13125032501605540642975_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.oss_java-driver-query-builder-4.7.2.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.oss_java-driver-query-builder-4.7.2.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.0.0.jar with timestamp 1605540642973
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.0.0.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp3723614752875010156.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-15238197191605540642973_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.spark_spark-cassandra-connector-driver_2.12-3.0.0.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.spark_spark-cassandra-connector-driver_2.12-3.0.0.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.hdrhistogram_HdrHistogram-2.1.11.jar with timestamp 1605540642974
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.hdrhistogram_HdrHistogram-2.1.11.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp8448041590503084148.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-21250691501605540642974_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.hdrhistogram_HdrHistogram-2.1.11.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.hdrhistogram_HdrHistogram-2.1.11.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.oss_java-driver-mapper-runtime-4.7.2.jar with timestamp 1605540642973
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.oss_java-driver-mapper-runtime-4.7.2.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp9798090047361463733.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-15772384781605540642973_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.oss_java-driver-mapper-runtime-4.7.2.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.oss_java-driver-mapper-runtime-4.7.2.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/spark-cassandra_2.12-0.1.0-SNAPSHOT.jar with timestamp 1605540642975
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/spark-cassandra_2.12-0.1.0-SNAPSHOT.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp2364890365083293044.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/20894940941605540642975_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./spark-cassandra_2.12-0.1.0-SNAPSHOT.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./spark-cassandra_2.12-0.1.0-SNAPSHOT.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.typesafe_config-1.3.4.jar with timestamp 1605540642974
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.typesafe_config-1.3.4.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp14180647938652234011.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-20529540751605540642974_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.typesafe_config-1.3.4.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.typesafe_config-1.3.4.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1605540642974
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp3483254882754601436.tmp
20/11/16 15:30:57 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-18010751891605540642974_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.scala-lang_scala-reflect-2.12.11.jar
20/11/16 15:30:57 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.scala-lang_scala-reflect-2.12.11.jar to class loader
20/11/16 15:30:57 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.oss_java-driver-core-shaded-4.7.2.jar with timestamp 1605540642973
20/11/16 15:30:57 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.oss_java-driver-core-shaded-4.7.2.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp3387645267554443759.tmp
20/11/16 15:30:58 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-16584130551605540642973_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.oss_java-driver-core-shaded-4.7.2.jar
20/11/16 15:30:58 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.oss_java-driver-core-shaded-4.7.2.jar to class loader
20/11/16 15:30:58 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.apache.commons_commons-lang3-3.9.jar with timestamp 1605540642973
20/11/16 15:30:58 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.apache.commons_commons-lang3-3.9.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp4328505715952627744.tmp
20/11/16 15:30:58 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-19351542831605540642973_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.apache.commons_commons-lang3-3.9.jar
20/11/16 15:30:58 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.apache.commons_commons-lang3-3.9.jar to class loader
20/11/16 15:30:58 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1605540642975
20/11/16 15:30:58 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp1319715948204326700.tmp
20/11/16 15:30:58 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/7344838901605540642975_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.google.code.findbugs_jsr305-3.0.2.jar
20/11/16 15:30:58 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.google.code.findbugs_jsr305-3.0.2.jar to class loader
20/11/16 15:30:58 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/io.dropwizard.metrics_metrics-core-4.0.5.jar with timestamp 1605540642974
20/11/16 15:30:58 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/io.dropwizard.metrics_metrics-core-4.0.5.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp6381842053956850933.tmp
20/11/16 15:30:58 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/15535972021605540642974_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./io.dropwizard.metrics_metrics-core-4.0.5.jar
20/11/16 15:30:58 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./io.dropwizard.metrics_metrics-core-4.0.5.jar to class loader
20/11/16 15:30:58 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1605540642974
20/11/16 15:30:58 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/org.slf4j_slf4j-api-1.7.26.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp13493234021730328520.tmp
20/11/16 15:30:58 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-1133556361605540642974_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.slf4j_slf4j-api-1.7.26.jar
20/11/16 15:30:58 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./org.slf4j_slf4j-api-1.7.26.jar to class loader
20/11/16 15:30:58 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1605540642974
20/11/16 15:30:58 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp1992232796754278805.tmp
20/11/16 15:30:58 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/-838846901605540642974_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
20/11/16 15:30:58 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to class loader
20/11/16 15:30:58 INFO Executor: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.0.0.jar with timestamp 1605540642972
20/11/16 15:30:58 INFO Utils: Fetching spark://ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.0.0.jar to /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/fetchFileTemp12299604508093897862.tmp
20/11/16 15:30:58 INFO Utils: Copying /tmp/spark-908d4f5c-babe-43fc-8149-dfbbe029baa2/executor-2b3bc1bd-a1cb-4004-941f-05fd76d9555a/spark-44b63951-c1f0-421a-9d5c-c49672131fc5/14157015281605540642972_cache to /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.spark_spark-cassandra-connector_2.12-3.0.0.jar
20/11/16 15:30:58 INFO Executor: Adding file:/workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./com.datastax.spark_spark-cassandra-connector_2.12-3.0.0.jar to class loader
20/11/16 15:30:58 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
20/11/16 15:30:58 INFO TransportClientFactory: Successfully created connection to ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64/10.8.4.68:42921 after 3 ms (0 ms spent in bootstraps)
20/11/16 15:30:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 434.4 MiB)
20/11/16 15:30:58 INFO TorrentBroadcast: Reading broadcast variable 0 took 158 ms
20/11/16 15:30:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 26.0 KiB, free 434.4 MiB)
20/11/16 15:30:59 INFO CodeGenerator: Code generated in 280.125013 ms
20/11/16 15:30:59 INFO CodeGenerator: Code generated in 19.040114 ms
20/11/16 15:30:59 INFO CodeGenerator: Code generated in 18.021026 ms
20/11/16 15:30:59 INFO CodeGenerator: Code generated in 39.506459 ms
20/11/16 15:31:01 INFO CassandraConnectionFactory: Found the secure-connect-demo.zip locally at /workspace/cassandra.realtime/spark/spark-3.0.1-bin-hadoop2.7/work/app-20201116153043-0013/0/./secure-connect-demo.zip, using this local file.
20/11/16 15:31:02 INFO DefaultMavenCoordinates: DataStax Java driver for Apache Cassandra(R) (com.datastax.oss:java-driver-core-shaded) version 4.7.2
20/11/16 15:31:02 INFO InternalDriverContext: Could not register Graph extensions; this is normal if Tinkerpop was explicitly excluded from classpath
20/11/16 15:31:02 INFO Native: Unable to load JNR native implementation. This could be normal if JNR is excluded from the classpath
java.lang.NoClassDefFoundError: jnr/posix/POSIXHandler
	at com.datastax.oss.driver.internal.core.os.Native$LibcLoader.load(Native.java:42)
	at com.datastax.oss.driver.internal.core.os.Native.<clinit>(Native.java:59)
	at com.datastax.oss.driver.internal.core.time.Clock.getInstance(Clock.java:34)
	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.buildClock(MonotonicTimestampGenerator.java:109)
	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.<init>(MonotonicTimestampGenerator.java:43)
	at com.datastax.oss.driver.internal.core.time.AtomicTimestampGenerator.<init>(AtomicTimestampGenerator.java:52)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:246)
	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:108)
	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.buildTimestampGenerator(DefaultDriverContext.java:368)
	at com.datastax.oss.driver.internal.core.util.concurrent.LazyReference.get(LazyReference.java:55)
	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.getTimestampGenerator(DefaultDriverContext.java:743)
	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.init(DefaultSession.java:349)
	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.access$1100(DefaultSession.java:300)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.lambda$init$0(DefaultSession.java:146)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.run(PromiseTask.java:106)
	at com.datastax.oss.driver.shaded.netty.channel.DefaultEventLoop.run(DefaultEventLoop.java:54)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.lang.ClassNotFoundException: jnr.posix.POSIXHandler
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:471)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:588)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)
	... 25 more
20/11/16 15:31:02 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
20/11/16 15:31:06 INFO CassandraConnector: Connected to Cassandra cluster.
20/11/16 15:31:07 ERROR Utils: Aborting task
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$7(WriteToDataSourceV2Exec.scala:438)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:477)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:385)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 30 more
20/11/16 15:31:07 ERROR Utils: Aborting task
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$7(WriteToDataSourceV2Exec.scala:438)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:477)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:385)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 30 more
20/11/16 15:31:07 ERROR Utils: Aborting task
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$7(WriteToDataSourceV2Exec.scala:438)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:477)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:385)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 30 more
20/11/16 15:31:07 ERROR DataWritingSparkTask: Aborting commit for partition 1 (task 1, attempt 0, stage 0.0)
20/11/16 15:31:07 ERROR DataWritingSparkTask: Aborting commit for partition 2 (task 2, attempt 0, stage 0.0)
20/11/16 15:31:07 ERROR DataWritingSparkTask: Aborting commit for partition 3 (task 3, attempt 0, stage 0.0)
20/11/16 15:31:07 ERROR DataWritingSparkTask: Aborted commit for partition 1 (task 1, attempt 0, stage 0.0)
20/11/16 15:31:07 ERROR DataWritingSparkTask: Aborted commit for partition 3 (task 3, attempt 0, stage 0.0)
20/11/16 15:31:07 ERROR DataWritingSparkTask: Aborted commit for partition 2 (task 2, attempt 0, stage 0.0)
20/11/16 15:31:07 ERROR Executor: Exception in task 3.0 in stage 0.0 (TID 3)
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$7(WriteToDataSourceV2Exec.scala:438)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:477)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:385)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 30 more
20/11/16 15:31:07 ERROR Executor: Exception in task 2.0 in stage 0.0 (TID 2)
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$7(WriteToDataSourceV2Exec.scala:438)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:477)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:385)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 30 more
20/11/16 15:31:07 ERROR Executor: Exception in task 1.0 in stage 0.0 (TID 1)
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$7(WriteToDataSourceV2Exec.scala:438)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:477)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:385)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 30 more
20/11/16 15:31:07 INFO CodeGenerator: Code generated in 58.154123 ms
20/11/16 15:31:07 INFO CoarseGrainedExecutorBackend: Got assigned task 5
20/11/16 15:31:07 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
20/11/16 15:31:07 INFO CoarseGrainedExecutorBackend: Got assigned task 6
20/11/16 15:31:07 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
20/11/16 15:31:07 INFO CoarseGrainedExecutorBackend: Got assigned task 7
20/11/16 15:31:07 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
20/11/16 15:31:07 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 0, attempt 0, stage 0.0)
20/11/16 15:31:07 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 4, attempt 0, stage 0.0)
20/11/16 15:31:08 INFO DataWritingSparkTask: Committed partition 4 (task 4, attempt 0, stage 0.0)
20/11/16 15:31:08 INFO DataWritingSparkTask: Committed partition 0 (task 0, attempt 0, stage 0.0)
20/11/16 15:31:08 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1660 bytes result sent to driver
20/11/16 15:31:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1660 bytes result sent to driver
20/11/16 15:31:08 INFO CoarseGrainedExecutorBackend: Got assigned task 8
20/11/16 15:31:08 INFO Executor: Running task 1.1 in stage 0.0 (TID 8)
20/11/16 15:31:08 INFO CoarseGrainedExecutorBackend: Got assigned task 9
20/11/16 15:31:08 INFO Executor: Running task 3.1 in stage 0.0 (TID 9)
20/11/16 15:31:08 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 5, attempt 0, stage 0.0)
20/11/16 15:31:08 ERROR Utils: Aborting task
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$7(WriteToDataSourceV2Exec.scala:438)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:477)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:385)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 30 more
20/11/16 15:31:08 ERROR DataWritingSparkTask: Aborting commit for partition 6 (task 6, attempt 0, stage 0.0)
20/11/16 15:31:08 ERROR DataWritingSparkTask: Aborted commit for partition 6 (task 6, attempt 0, stage 0.0)
20/11/16 15:31:08 ERROR Executor: Exception in task 6.0 in stage 0.0 (TID 6)
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.$anonfun$run$7(WriteToDataSourceV2Exec.scala:438)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:477)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:385)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 30 more
20/11/16 15:31:08 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 9, attempt 1, stage 0.0)
20/11/16 15:31:08 INFO DataWritingSparkTask: Committed partition 3 (task 9, attempt 1, stage 0.0)
20/11/16 15:31:08 INFO Executor: Finished task 3.1 in stage 0.0 (TID 9). 1617 bytes result sent to driver
20/11/16 15:31:08 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 7, attempt 0, stage 0.0)
20/11/16 15:31:08 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 8, attempt 1, stage 0.0)
20/11/16 15:31:08 INFO CoarseGrainedExecutorBackend: Got assigned task 10
20/11/16 15:31:08 INFO Executor: Running task 2.1 in stage 0.0 (TID 10)
20/11/16 15:31:08 INFO CoarseGrainedExecutorBackend: Got assigned task 11
20/11/16 15:31:08 INFO Executor: Running task 8.0 in stage 0.0 (TID 11)
20/11/16 15:31:08 INFO DataWritingSparkTask: Committed partition 7 (task 7, attempt 0, stage 0.0)
20/11/16 15:31:08 INFO DataWritingSparkTask: Committed partition 5 (task 5, attempt 0, stage 0.0)
20/11/16 15:31:08 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1617 bytes result sent to driver
20/11/16 15:31:08 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1617 bytes result sent to driver
20/11/16 15:31:08 INFO DataWritingSparkTask: Committed partition 1 (task 8, attempt 1, stage 0.0)
20/11/16 15:31:08 INFO Executor: Finished task 1.1 in stage 0.0 (TID 8). 1617 bytes result sent to driver
20/11/16 15:31:08 INFO CoarseGrainedExecutorBackend: Got assigned task 12
20/11/16 15:31:08 INFO Executor: Running task 6.1 in stage 0.0 (TID 12)
20/11/16 15:31:08 INFO CoarseGrainedExecutorBackend: Got assigned task 13
20/11/16 15:31:08 INFO Executor: Running task 9.0 in stage 0.0 (TID 13)
20/11/16 15:31:08 INFO CoarseGrainedExecutorBackend: Got assigned task 14
20/11/16 15:31:08 INFO Executor: Running task 10.0 in stage 0.0 (TID 14)
20/11/16 15:31:08 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 11, attempt 0, stage 0.0)
20/11/16 15:31:08 INFO DataWritingSparkTask: Committed partition 8 (task 11, attempt 0, stage 0.0)
20/11/16 15:31:08 INFO Executor: Finished task 8.0 in stage 0.0 (TID 11). 1574 bytes result sent to driver
20/11/16 15:31:08 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 12, attempt 1, stage 0.0)
20/11/16 15:31:08 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 14, attempt 0, stage 0.0)
20/11/16 15:31:08 INFO DataWritingSparkTask: Committed partition 6 (task 12, attempt 1, stage 0.0)
20/11/16 15:31:08 INFO DataWritingSparkTask: Committed partition 10 (task 14, attempt 0, stage 0.0)
20/11/16 15:31:08 INFO Executor: Finished task 10.0 in stage 0.0 (TID 14). 1574 bytes result sent to driver
20/11/16 15:31:08 INFO Executor: Finished task 6.1 in stage 0.0 (TID 12). 1574 bytes result sent to driver
20/11/16 15:31:08 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 10, attempt 1, stage 0.0)
20/11/16 15:31:09 INFO DataWritingSparkTask: Committed partition 2 (task 10, attempt 1, stage 0.0)
20/11/16 15:31:09 INFO Executor: Finished task 2.1 in stage 0.0 (TID 10). 1574 bytes result sent to driver
20/11/16 15:31:09 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 13, attempt 0, stage 0.0)
20/11/16 15:31:09 INFO DataWritingSparkTask: Committed partition 9 (task 13, attempt 0, stage 0.0)
20/11/16 15:31:09 INFO Executor: Finished task 9.0 in stage 0.0 (TID 13). 1574 bytes result sent to driver
20/11/16 15:31:11 INFO CoarseGrainedExecutorBackend: Got assigned task 15
20/11/16 15:31:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 15)
20/11/16 15:31:11 INFO CoarseGrainedExecutorBackend: Got assigned task 16
20/11/16 15:31:11 INFO CoarseGrainedExecutorBackend: Got assigned task 17
20/11/16 15:31:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 16)
20/11/16 15:31:11 INFO CoarseGrainedExecutorBackend: Got assigned task 18
20/11/16 15:31:11 INFO Executor: Running task 3.0 in stage 1.0 (TID 18)
20/11/16 15:31:11 INFO CoarseGrainedExecutorBackend: Got assigned task 19
20/11/16 15:31:11 INFO Executor: Running task 4.0 in stage 1.0 (TID 19)
20/11/16 15:31:11 INFO Executor: Running task 2.0 in stage 1.0 (TID 17)
20/11/16 15:31:11 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
20/11/16 15:31:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 434.4 MiB)
20/11/16 15:31:11 INFO TorrentBroadcast: Reading broadcast variable 1 took 20 ms
20/11/16 15:31:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 33.4 KiB, free 434.4 MiB)
20/11/16 15:31:12 INFO CodeGenerator: Code generated in 31.408702 ms
20/11/16 15:31:12 INFO CodeGenerator: Code generated in 10.094932 ms
20/11/16 15:31:12 INFO CodeGenerator: Code generated in 54.37107 ms
20/11/16 15:31:12 INFO CodeGenerator: Code generated in 11.988364 ms
20/11/16 15:31:12 INFO CodeGenerator: Code generated in 8.19418 ms
20/11/16 15:31:12 INFO CodeGenerator: Code generated in 8.392869 ms
20/11/16 15:31:12 ERROR Executor: Exception in task 2.0 in stage 1.0 (TID 17)
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at jdk.internal.reflect.GeneratedMethodAccessor59.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 31 more
20/11/16 15:31:12 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 15)
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at jdk.internal.reflect.GeneratedMethodAccessor59.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 31 more
20/11/16 15:31:12 ERROR Executor: Exception in task 4.0 in stage 1.0 (TID 19)
java.io.IOException: Invalid request, too many continuous paging sessions are already running: 2. This error may be intermittent, if there are other applications using continuous paging wait for them to finish and re-execute. If the error persists adjust your DSE server setting `continuous_paging.max_concurrent_sessions` or lower the parallelism level of this job (reduce the number of executors and/or assigned cores) or disable continuous paging for this app with spark.dse.continuousPagingEnabled.
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:108)
	at com.datastax.spark.connector.datasource.ScanHelper$.fetchTokenRange(ScanHelper.scala:79)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.$anonfun$getIterator$1(CassandraScanPartitionReaderFactory.scala:108)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at com.datastax.spark.connector.datasource.CassandraPartitionReaderBase.next(CassandraScanPartitionReaderFactory.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:79)
	at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:112)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.datastax.oss.driver.api.core.servererrors.InvalidQueryException: Invalid request, too many continuous paging sessions are already running: 2
	at com.datastax.oss.driver.api.core.servererrors.InvalidQueryException.copy(InvalidQueryException.java:48)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:56)
	at com.datastax.dse.driver.internal.core.cql.continuous.ContinuousCqlRequestSyncProcessor.process(ContinuousCqlRequestSyncProcessor.java:30)
	at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230)
	at com.datastax.dse.driver.api.core.cql.continuous.ContinuousSession.executeContinuously(ContinuousSession.java:88)
	at jdk.internal.reflect.GeneratedMethodAccessor59.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:43)
	at com.sun.proxy.$Proxy27.executeContinuously(Unknown Source)
	at com.datastax.bdp.spark.ContinuousPagingScanner.scan(ContinuousPagingScanner.scala:99)
	... 31 more
20/11/16 15:31:12 INFO CodeGenerator: Code generated in 14.819625 ms
20/11/16 15:31:12 INFO Executor: Finished task 3.0 in stage 1.0 (TID 18). 2392 bytes result sent to driver
20/11/16 15:31:12 INFO CoarseGrainedExecutorBackend: Got assigned task 20
20/11/16 15:31:12 INFO Executor: Running task 5.0 in stage 1.0 (TID 20)
20/11/16 15:31:12 INFO CoarseGrainedExecutorBackend: Got assigned task 21
20/11/16 15:31:12 INFO Executor: Running task 0.1 in stage 1.0 (TID 21)
20/11/16 15:31:12 INFO CoarseGrainedExecutorBackend: Got assigned task 22
20/11/16 15:31:12 INFO Executor: Running task 4.1 in stage 1.0 (TID 22)
20/11/16 15:31:12 INFO CoarseGrainedExecutorBackend: Got assigned task 23
20/11/16 15:31:12 INFO Executor: Running task 2.1 in stage 1.0 (TID 23)
20/11/16 15:31:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 16). 2521 bytes result sent to driver
20/11/16 15:31:12 INFO CoarseGrainedExecutorBackend: Got assigned task 24
20/11/16 15:31:12 INFO Executor: Running task 6.0 in stage 1.0 (TID 24)
20/11/16 15:31:12 INFO Executor: Finished task 6.0 in stage 1.0 (TID 24). 2349 bytes result sent to driver
20/11/16 15:31:12 INFO Executor: Finished task 5.0 in stage 1.0 (TID 20). 2392 bytes result sent to driver
20/11/16 15:31:12 INFO CoarseGrainedExecutorBackend: Got assigned task 25
20/11/16 15:31:12 INFO Executor: Running task 7.0 in stage 1.0 (TID 25)
20/11/16 15:31:12 INFO CoarseGrainedExecutorBackend: Got assigned task 26
20/11/16 15:31:12 INFO Executor: Running task 8.0 in stage 1.0 (TID 26)
20/11/16 15:31:12 INFO Executor: Finished task 0.1 in stage 1.0 (TID 21). 2521 bytes result sent to driver
20/11/16 15:31:12 INFO Executor: Finished task 2.1 in stage 1.0 (TID 23). 2478 bytes result sent to driver
20/11/16 15:31:12 INFO Executor: Finished task 4.1 in stage 1.0 (TID 22). 2521 bytes result sent to driver
20/11/16 15:31:12 INFO CoarseGrainedExecutorBackend: Got assigned task 27
20/11/16 15:31:12 INFO Executor: Running task 9.0 in stage 1.0 (TID 27)
20/11/16 15:31:12 INFO CoarseGrainedExecutorBackend: Got assigned task 28
20/11/16 15:31:12 INFO Executor: Running task 10.0 in stage 1.0 (TID 28)
20/11/16 15:31:12 INFO Executor: Finished task 7.0 in stage 1.0 (TID 25). 2521 bytes result sent to driver
20/11/16 15:31:12 INFO Executor: Finished task 9.0 in stage 1.0 (TID 27). 2478 bytes result sent to driver
20/11/16 15:31:12 INFO Executor: Finished task 8.0 in stage 1.0 (TID 26). 2521 bytes result sent to driver
20/11/16 15:31:12 INFO Executor: Finished task 10.0 in stage 1.0 (TID 28). 2478 bytes result sent to driver
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 29
20/11/16 15:31:13 INFO Executor: Running task 8.0 in stage 2.0 (TID 29)
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 30
20/11/16 15:31:13 INFO Executor: Running task 10.0 in stage 2.0 (TID 30)
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 31
20/11/16 15:31:13 INFO Executor: Running task 41.0 in stage 2.0 (TID 31)
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 32
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 33
20/11/16 15:31:13 INFO Executor: Running task 46.0 in stage 2.0 (TID 32)
20/11/16 15:31:13 INFO Executor: Running task 59.0 in stage 2.0 (TID 33)
20/11/16 15:31:13 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
20/11/16 15:31:13 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
20/11/16 15:31:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 434.3 MiB)
20/11/16 15:31:13 INFO TorrentBroadcast: Reading broadcast variable 2 took 9 ms
20/11/16 15:31:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 33.5 KiB, free 434.3 MiB)
20/11/16 15:31:13 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/11/16 15:31:13 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/11/16 15:31:13 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/11/16 15:31:13 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/11/16 15:31:13 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/11/16 15:31:13 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ws-6a3f44d5-fabe-47c5-bbe9-5ffec88d8e64:37921)
20/11/16 15:31:13 INFO MapOutputTrackerWorker: Got the output locations
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 2 (144.0 B) non-empty blocks including 2 (144.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 4 (288.0 B) non-empty blocks including 4 (288.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 5 (400.0 B) non-empty blocks including 5 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 33 ms
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 33 ms
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 33 ms
20/11/16 15:31:13 INFO CodeGenerator: Code generated in 23.485515 ms
20/11/16 15:31:13 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 31, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO DataWritingSparkTask: Committed partition 41 (task 31, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO Executor: Finished task 41.0 in stage 2.0 (TID 31). 3491 bytes result sent to driver
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 34
20/11/16 15:31:13 INFO Executor: Running task 77.0 in stage 2.0 (TID 34)
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 2 (144.0 B) non-empty blocks including 2 (144.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/11/16 15:31:13 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 32, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 29, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 30, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 33, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO DataWritingSparkTask: Committed partition 46 (task 32, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO DataWritingSparkTask: Committed partition 10 (task 30, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO Executor: Finished task 46.0 in stage 2.0 (TID 32). 3491 bytes result sent to driver
20/11/16 15:31:13 INFO DataWritingSparkTask: Committed partition 8 (task 29, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO DataWritingSparkTask: Committed partition 59 (task 33, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO Executor: Finished task 10.0 in stage 2.0 (TID 30). 3491 bytes result sent to driver
20/11/16 15:31:13 INFO Executor: Finished task 8.0 in stage 2.0 (TID 29). 3491 bytes result sent to driver
20/11/16 15:31:13 INFO Executor: Finished task 59.0 in stage 2.0 (TID 33). 3491 bytes result sent to driver
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 35
20/11/16 15:31:13 INFO Executor: Running task 83.0 in stage 2.0 (TID 35)
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 36
20/11/16 15:31:13 INFO Executor: Running task 91.0 in stage 2.0 (TID 36)
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 37
20/11/16 15:31:13 INFO Executor: Running task 148.0 in stage 2.0 (TID 37)
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 38
20/11/16 15:31:13 INFO Executor: Running task 149.0 in stage 2.0 (TID 38)
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 2 (144.0 B) non-empty blocks including 2 (144.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 3 (264.0 B) non-empty blocks including 3 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:13 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 34, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO DataWritingSparkTask: Committed partition 77 (task 34, attempt 0, stage 2.0)
20/11/16 15:31:13 INFO Executor: Finished task 77.0 in stage 2.0 (TID 34). 3491 bytes result sent to driver
20/11/16 15:31:13 INFO CoarseGrainedExecutorBackend: Got assigned task 39
20/11/16 15:31:13 INFO Executor: Running task 170.0 in stage 2.0 (TID 39)
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Getting 2 (144.0 B) non-empty blocks including 2 (144.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 37, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 38, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 36, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 35, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 148 (task 37, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 91 (task 36, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 149 (task 38, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 83 (task 35, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO Executor: Finished task 148.0 in stage 2.0 (TID 37). 3534 bytes result sent to driver
20/11/16 15:31:14 INFO Executor: Finished task 149.0 in stage 2.0 (TID 38). 3534 bytes result sent to driver
20/11/16 15:31:14 INFO Executor: Finished task 91.0 in stage 2.0 (TID 36). 3534 bytes result sent to driver
20/11/16 15:31:14 INFO Executor: Finished task 83.0 in stage 2.0 (TID 35). 3534 bytes result sent to driver
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 40
20/11/16 15:31:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 40)
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 41
20/11/16 15:31:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 41)
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 42
20/11/16 15:31:14 INFO Executor: Running task 2.0 in stage 2.0 (TID 42)
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 43
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO Executor: Running task 3.0 in stage 2.0 (TID 43)
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 39, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 170 (task 39, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO Executor: Finished task 170.0 in stage 2.0 (TID 39). 3534 bytes result sent to driver
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 44
20/11/16 15:31:14 INFO Executor: Running task 4.0 in stage 2.0 (TID 44)
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 43, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 40, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 3 (task 43, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 0 (task 40, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 41, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 42, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 1 (task 41, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 2 (task 42, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 40). 3491 bytes result sent to driver
20/11/16 15:31:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 41). 3491 bytes result sent to driver
20/11/16 15:31:14 INFO Executor: Finished task 3.0 in stage 2.0 (TID 43). 3491 bytes result sent to driver
20/11/16 15:31:14 INFO Executor: Finished task 2.0 in stage 2.0 (TID 42). 3491 bytes result sent to driver
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 45
20/11/16 15:31:14 INFO Executor: Running task 5.0 in stage 2.0 (TID 45)
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 46
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 47
20/11/16 15:31:14 INFO Executor: Running task 7.0 in stage 2.0 (TID 47)
20/11/16 15:31:14 INFO Executor: Running task 6.0 in stage 2.0 (TID 46)
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 48
20/11/16 15:31:14 INFO Executor: Running task 9.0 in stage 2.0 (TID 48)
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 44, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 4 (task 44, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO Executor: Finished task 4.0 in stage 2.0 (TID 44). 3491 bytes result sent to driver
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 49
20/11/16 15:31:14 INFO Executor: Running task 11.0 in stage 2.0 (TID 49)
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 46, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 6 (task 46, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 45, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 47, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 5 (task 45, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 7 (task 47, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO Executor: Finished task 6.0 in stage 2.0 (TID 46). 3491 bytes result sent to driver
20/11/16 15:31:14 INFO Executor: Finished task 5.0 in stage 2.0 (TID 45). 3491 bytes result sent to driver
20/11/16 15:31:14 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 48, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO DataWritingSparkTask: Committed partition 9 (task 48, attempt 0, stage 2.0)
20/11/16 15:31:14 INFO Executor: Finished task 7.0 in stage 2.0 (TID 47). 3491 bytes result sent to driver
20/11/16 15:31:14 INFO Executor: Finished task 9.0 in stage 2.0 (TID 48). 3491 bytes result sent to driver
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 50
20/11/16 15:31:14 INFO Executor: Running task 12.0 in stage 2.0 (TID 50)
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 51
20/11/16 15:31:14 INFO Executor: Running task 13.0 in stage 2.0 (TID 51)
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 52
20/11/16 15:31:14 INFO Executor: Running task 14.0 in stage 2.0 (TID 52)
20/11/16 15:31:14 INFO CoarseGrainedExecutorBackend: Got assigned task 53
20/11/16 15:31:14 INFO Executor: Running task 15.0 in stage 2.0 (TID 53)
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 49, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 11 (task 49, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO Executor: Finished task 11.0 in stage 2.0 (TID 49). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 54
20/11/16 15:31:15 INFO Executor: Running task 16.0 in stage 2.0 (TID 54)
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 52, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 14 (task 52, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO Executor: Finished task 14.0 in stage 2.0 (TID 52). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 53, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 50, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 15 (task 53, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 12 (task 50, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 55
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 51, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO Executor: Running task 17.0 in stage 2.0 (TID 55)
20/11/16 15:31:15 INFO Executor: Finished task 12.0 in stage 2.0 (TID 50). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 13 (task 51, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO Executor: Finished task 13.0 in stage 2.0 (TID 51). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO Executor: Finished task 15.0 in stage 2.0 (TID 53). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 56
20/11/16 15:31:15 INFO Executor: Running task 18.0 in stage 2.0 (TID 56)
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 57
20/11/16 15:31:15 INFO Executor: Running task 19.0 in stage 2.0 (TID 57)
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 58
20/11/16 15:31:15 INFO Executor: Running task 20.0 in stage 2.0 (TID 58)
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 54, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 16 (task 54, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO Executor: Finished task 16.0 in stage 2.0 (TID 54). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 59
20/11/16 15:31:15 INFO Executor: Running task 21.0 in stage 2.0 (TID 59)
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 58, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 20 (task 58, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO Executor: Finished task 20.0 in stage 2.0 (TID 58). 3534 bytes result sent to driver
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 56, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 18 (task 56, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 57, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 19 (task 57, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 55, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 17 (task 55, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO Executor: Finished task 17.0 in stage 2.0 (TID 55). 3534 bytes result sent to driver
20/11/16 15:31:15 INFO Executor: Finished task 18.0 in stage 2.0 (TID 56). 3534 bytes result sent to driver
20/11/16 15:31:15 INFO Executor: Finished task 19.0 in stage 2.0 (TID 57). 3534 bytes result sent to driver
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 60
20/11/16 15:31:15 INFO Executor: Running task 22.0 in stage 2.0 (TID 60)
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 61
20/11/16 15:31:15 INFO Executor: Running task 23.0 in stage 2.0 (TID 61)
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 62
20/11/16 15:31:15 INFO Executor: Running task 24.0 in stage 2.0 (TID 62)
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 63
20/11/16 15:31:15 INFO Executor: Running task 25.0 in stage 2.0 (TID 63)
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 59, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 21 (task 59, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO Executor: Finished task 21.0 in stage 2.0 (TID 59). 3534 bytes result sent to driver
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 64
20/11/16 15:31:15 INFO Executor: Running task 26.0 in stage 2.0 (TID 64)
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 60, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 63, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 22 (task 60, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 25 (task 63, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO Executor: Finished task 22.0 in stage 2.0 (TID 60). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO Executor: Finished task 25.0 in stage 2.0 (TID 63). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 61, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 23 (task 61, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 65
20/11/16 15:31:15 INFO Executor: Running task 27.0 in stage 2.0 (TID 65)
20/11/16 15:31:15 INFO Executor: Finished task 23.0 in stage 2.0 (TID 61). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 62, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 24 (task 62, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 66
20/11/16 15:31:15 INFO Executor: Running task 28.0 in stage 2.0 (TID 66)
20/11/16 15:31:15 INFO Executor: Finished task 24.0 in stage 2.0 (TID 62). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 67
20/11/16 15:31:15 INFO Executor: Running task 29.0 in stage 2.0 (TID 67)
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 68
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
20/11/16 15:31:15 INFO Executor: Running task 30.0 in stage 2.0 (TID 68)
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:15 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 64, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO DataWritingSparkTask: Committed partition 26 (task 64, attempt 0, stage 2.0)
20/11/16 15:31:15 INFO Executor: Finished task 26.0 in stage 2.0 (TID 64). 3491 bytes result sent to driver
20/11/16 15:31:15 INFO CoarseGrainedExecutorBackend: Got assigned task 69
20/11/16 15:31:15 INFO Executor: Running task 31.0 in stage 2.0 (TID 69)
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 68, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 30 (task 68, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 67, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 66, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 29 (task 67, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 28 (task 66, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 65, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO Executor: Finished task 30.0 in stage 2.0 (TID 68). 3491 bytes result sent to driver
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 27 (task 65, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO Executor: Finished task 28.0 in stage 2.0 (TID 66). 3491 bytes result sent to driver
20/11/16 15:31:16 INFO Executor: Finished task 29.0 in stage 2.0 (TID 67). 3491 bytes result sent to driver
20/11/16 15:31:16 INFO Executor: Finished task 27.0 in stage 2.0 (TID 65). 3491 bytes result sent to driver
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 70
20/11/16 15:31:16 INFO Executor: Running task 32.0 in stage 2.0 (TID 70)
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 71
20/11/16 15:31:16 INFO Executor: Running task 33.0 in stage 2.0 (TID 71)
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 72
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO Executor: Running task 34.0 in stage 2.0 (TID 72)
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 73
20/11/16 15:31:16 INFO Executor: Running task 35.0 in stage 2.0 (TID 73)
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 69, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 31 (task 69, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO Executor: Finished task 31.0 in stage 2.0 (TID 69). 3491 bytes result sent to driver
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 74
20/11/16 15:31:16 INFO Executor: Running task 36.0 in stage 2.0 (TID 74)
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 70, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 71, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 32 (task 70, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 72, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 73, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 33 (task 71, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 34 (task 72, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 35 (task 73, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO Executor: Finished task 32.0 in stage 2.0 (TID 70). 3491 bytes result sent to driver
20/11/16 15:31:16 INFO Executor: Finished task 34.0 in stage 2.0 (TID 72). 3491 bytes result sent to driver
20/11/16 15:31:16 INFO Executor: Finished task 35.0 in stage 2.0 (TID 73). 3491 bytes result sent to driver
20/11/16 15:31:16 INFO Executor: Finished task 33.0 in stage 2.0 (TID 71). 3491 bytes result sent to driver
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 75
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 76
20/11/16 15:31:16 INFO Executor: Running task 38.0 in stage 2.0 (TID 76)
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 77
20/11/16 15:31:16 INFO Executor: Running task 39.0 in stage 2.0 (TID 77)
20/11/16 15:31:16 INFO Executor: Running task 37.0 in stage 2.0 (TID 75)
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 78
20/11/16 15:31:16 INFO Executor: Running task 40.0 in stage 2.0 (TID 78)
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 74, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 36 (task 74, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO Executor: Finished task 36.0 in stage 2.0 (TID 74). 3491 bytes result sent to driver
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 79
20/11/16 15:31:16 INFO Executor: Running task 42.0 in stage 2.0 (TID 79)
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 75, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 37 (task 75, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 76, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 38 (task 76, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO Executor: Finished task 37.0 in stage 2.0 (TID 75). 3534 bytes result sent to driver
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 78, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO Executor: Finished task 38.0 in stage 2.0 (TID 76). 3534 bytes result sent to driver
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 40 (task 78, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 77, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 39 (task 77, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO Executor: Finished task 40.0 in stage 2.0 (TID 78). 3534 bytes result sent to driver
20/11/16 15:31:16 INFO Executor: Finished task 39.0 in stage 2.0 (TID 77). 3534 bytes result sent to driver
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 80
20/11/16 15:31:16 INFO Executor: Running task 43.0 in stage 2.0 (TID 80)
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 81
20/11/16 15:31:16 INFO Executor: Running task 44.0 in stage 2.0 (TID 81)
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 82
20/11/16 15:31:16 INFO Executor: Running task 45.0 in stage 2.0 (TID 82)
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 83
20/11/16 15:31:16 INFO Executor: Running task 47.0 in stage 2.0 (TID 83)
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/11/16 15:31:16 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 79, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO DataWritingSparkTask: Committed partition 42 (task 79, attempt 0, stage 2.0)
20/11/16 15:31:16 INFO Executor: Finished task 42.0 in stage 2.0 (TID 79). 3534 bytes result sent to driver
20/11/16 15:31:16 INFO CoarseGrainedExecutorBackend: Got assigned task 84
20/11/16 15:31:16 INFO Executor: Running task 48.0 in stage 2.0 (TID 84)
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 81, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 44 (task 81, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 82, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 80, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 83, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 45 (task 82, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 43 (task 80, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 47 (task 83, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO Executor: Finished task 44.0 in stage 2.0 (TID 81). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 45.0 in stage 2.0 (TID 82). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 43.0 in stage 2.0 (TID 80). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 47.0 in stage 2.0 (TID 83). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 85
20/11/16 15:31:17 INFO Executor: Running task 49.0 in stage 2.0 (TID 85)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 86
20/11/16 15:31:17 INFO Executor: Running task 50.0 in stage 2.0 (TID 86)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 87
20/11/16 15:31:17 INFO Executor: Running task 51.0 in stage 2.0 (TID 87)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 88
20/11/16 15:31:17 INFO Executor: Running task 52.0 in stage 2.0 (TID 88)
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 84, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 48 (task 84, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO Executor: Finished task 48.0 in stage 2.0 (TID 84). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 89
20/11/16 15:31:17 INFO Executor: Running task 53.0 in stage 2.0 (TID 89)
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 87, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 88, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 51 (task 87, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 86, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 85, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 52 (task 88, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 50 (task 86, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 49 (task 85, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO Executor: Finished task 51.0 in stage 2.0 (TID 87). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 52.0 in stage 2.0 (TID 88). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 50.0 in stage 2.0 (TID 86). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 49.0 in stage 2.0 (TID 85). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 90
20/11/16 15:31:17 INFO Executor: Running task 54.0 in stage 2.0 (TID 90)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 91
20/11/16 15:31:17 INFO Executor: Running task 55.0 in stage 2.0 (TID 91)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 92
20/11/16 15:31:17 INFO Executor: Running task 56.0 in stage 2.0 (TID 92)
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 93
20/11/16 15:31:17 INFO Executor: Running task 57.0 in stage 2.0 (TID 93)
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 89, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 53 (task 89, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO Executor: Finished task 53.0 in stage 2.0 (TID 89). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 94
20/11/16 15:31:17 INFO Executor: Running task 58.0 in stage 2.0 (TID 94)
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 91, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 92, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 55 (task 91, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 56 (task 92, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 90, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 93, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 54 (task 90, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 57 (task 93, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO Executor: Finished task 55.0 in stage 2.0 (TID 91). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 56.0 in stage 2.0 (TID 92). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 54.0 in stage 2.0 (TID 90). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 57.0 in stage 2.0 (TID 93). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 95
20/11/16 15:31:17 INFO Executor: Running task 60.0 in stage 2.0 (TID 95)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 96
20/11/16 15:31:17 INFO Executor: Running task 61.0 in stage 2.0 (TID 96)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 97
20/11/16 15:31:17 INFO Executor: Running task 62.0 in stage 2.0 (TID 97)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 98
20/11/16 15:31:17 INFO Executor: Running task 63.0 in stage 2.0 (TID 98)
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 94, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 58 (task 94, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO Executor: Finished task 58.0 in stage 2.0 (TID 94). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 99
20/11/16 15:31:17 INFO Executor: Running task 64.0 in stage 2.0 (TID 99)
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 98, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 63 (task 98, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 96, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 97, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 61 (task 96, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 95, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 62 (task 97, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO DataWritingSparkTask: Committed partition 60 (task 95, attempt 0, stage 2.0)
20/11/16 15:31:17 INFO Executor: Finished task 63.0 in stage 2.0 (TID 98). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 61.0 in stage 2.0 (TID 96). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 62.0 in stage 2.0 (TID 97). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO Executor: Finished task 60.0 in stage 2.0 (TID 95). 3491 bytes result sent to driver
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 100
20/11/16 15:31:17 INFO Executor: Running task 65.0 in stage 2.0 (TID 100)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 101
20/11/16 15:31:17 INFO Executor: Running task 66.0 in stage 2.0 (TID 101)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 102
20/11/16 15:31:17 INFO Executor: Running task 67.0 in stage 2.0 (TID 102)
20/11/16 15:31:17 INFO CoarseGrainedExecutorBackend: Got assigned task 103
20/11/16 15:31:17 INFO Executor: Running task 68.0 in stage 2.0 (TID 103)
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 99, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 64 (task 99, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO Executor: Finished task 64.0 in stage 2.0 (TID 99). 3534 bytes result sent to driver
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 104
20/11/16 15:31:18 INFO Executor: Running task 69.0 in stage 2.0 (TID 104)
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 101, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 66 (task 101, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO Executor: Finished task 66.0 in stage 2.0 (TID 101). 3534 bytes result sent to driver
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 100, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 65 (task 100, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 102, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 103, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 67 (task 102, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 68 (task 103, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO Executor: Finished task 65.0 in stage 2.0 (TID 100). 3534 bytes result sent to driver
20/11/16 15:31:18 INFO Executor: Finished task 67.0 in stage 2.0 (TID 102). 3534 bytes result sent to driver
20/11/16 15:31:18 INFO Executor: Finished task 68.0 in stage 2.0 (TID 103). 3534 bytes result sent to driver
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 105
20/11/16 15:31:18 INFO Executor: Running task 70.0 in stage 2.0 (TID 105)
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 106
20/11/16 15:31:18 INFO Executor: Running task 71.0 in stage 2.0 (TID 106)
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 107
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 108
20/11/16 15:31:18 INFO Executor: Running task 73.0 in stage 2.0 (TID 108)
20/11/16 15:31:18 INFO Executor: Running task 72.0 in stage 2.0 (TID 107)
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 104, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 69 (task 104, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO Executor: Finished task 69.0 in stage 2.0 (TID 104). 3491 bytes result sent to driver
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 109
20/11/16 15:31:18 INFO Executor: Running task 74.0 in stage 2.0 (TID 109)
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 108, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 73 (task 108, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 107, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 72 (task 107, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 106, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 105, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 71 (task 106, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO Executor: Finished task 73.0 in stage 2.0 (TID 108). 3491 bytes result sent to driver
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 70 (task 105, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO Executor: Finished task 72.0 in stage 2.0 (TID 107). 3491 bytes result sent to driver
20/11/16 15:31:18 INFO Executor: Finished task 70.0 in stage 2.0 (TID 105). 3491 bytes result sent to driver
20/11/16 15:31:18 INFO Executor: Finished task 71.0 in stage 2.0 (TID 106). 3491 bytes result sent to driver
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 110
20/11/16 15:31:18 INFO Executor: Running task 75.0 in stage 2.0 (TID 110)
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 111
20/11/16 15:31:18 INFO Executor: Running task 76.0 in stage 2.0 (TID 111)
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 112
20/11/16 15:31:18 INFO Executor: Running task 78.0 in stage 2.0 (TID 112)
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 113
20/11/16 15:31:18 INFO Executor: Running task 79.0 in stage 2.0 (TID 113)
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 109, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 74 (task 109, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO Executor: Finished task 74.0 in stage 2.0 (TID 109). 3491 bytes result sent to driver
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 114
20/11/16 15:31:18 INFO Executor: Running task 80.0 in stage 2.0 (TID 114)
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 113, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 79 (task 113, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 112, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 111, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 78 (task 112, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 110, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 76 (task 111, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO DataWritingSparkTask: Committed partition 75 (task 110, attempt 0, stage 2.0)
20/11/16 15:31:18 INFO Executor: Finished task 79.0 in stage 2.0 (TID 113). 3491 bytes result sent to driver
20/11/16 15:31:18 INFO Executor: Finished task 78.0 in stage 2.0 (TID 112). 3491 bytes result sent to driver
20/11/16 15:31:18 INFO Executor: Finished task 76.0 in stage 2.0 (TID 111). 3491 bytes result sent to driver
20/11/16 15:31:18 INFO Executor: Finished task 75.0 in stage 2.0 (TID 110). 3491 bytes result sent to driver
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 115
20/11/16 15:31:18 INFO Executor: Running task 81.0 in stage 2.0 (TID 115)
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 116
20/11/16 15:31:18 INFO Executor: Running task 82.0 in stage 2.0 (TID 116)
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 117
20/11/16 15:31:18 INFO Executor: Running task 84.0 in stage 2.0 (TID 117)
20/11/16 15:31:18 INFO CoarseGrainedExecutorBackend: Got assigned task 118
20/11/16 15:31:18 INFO Executor: Running task 85.0 in stage 2.0 (TID 118)
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 114, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 80 (task 114, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO Executor: Finished task 80.0 in stage 2.0 (TID 114). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 119
20/11/16 15:31:19 INFO Executor: Running task 86.0 in stage 2.0 (TID 119)
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 117, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 84 (task 117, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 118, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 116, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 115, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 85 (task 118, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 82 (task 116, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 81 (task 115, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO Executor: Finished task 84.0 in stage 2.0 (TID 117). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO Executor: Finished task 82.0 in stage 2.0 (TID 116). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO Executor: Finished task 81.0 in stage 2.0 (TID 115). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO Executor: Finished task 85.0 in stage 2.0 (TID 118). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 120
20/11/16 15:31:19 INFO Executor: Running task 87.0 in stage 2.0 (TID 120)
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 121
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 122
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 123
20/11/16 15:31:19 INFO Executor: Running task 90.0 in stage 2.0 (TID 123)
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO Executor: Running task 89.0 in stage 2.0 (TID 122)
20/11/16 15:31:19 INFO Executor: Running task 88.0 in stage 2.0 (TID 121)
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 119, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 86 (task 119, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO Executor: Finished task 86.0 in stage 2.0 (TID 119). 3534 bytes result sent to driver
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 124
20/11/16 15:31:19 INFO Executor: Running task 92.0 in stage 2.0 (TID 124)
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 121, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 123, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 88 (task 121, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 122, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 90 (task 123, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 120, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 89 (task 122, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 87 (task 120, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO Executor: Finished task 88.0 in stage 2.0 (TID 121). 3534 bytes result sent to driver
20/11/16 15:31:19 INFO Executor: Finished task 90.0 in stage 2.0 (TID 123). 3534 bytes result sent to driver
20/11/16 15:31:19 INFO Executor: Finished task 89.0 in stage 2.0 (TID 122). 3534 bytes result sent to driver
20/11/16 15:31:19 INFO Executor: Finished task 87.0 in stage 2.0 (TID 120). 3534 bytes result sent to driver
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 125
20/11/16 15:31:19 INFO Executor: Running task 93.0 in stage 2.0 (TID 125)
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 126
20/11/16 15:31:19 INFO Executor: Running task 94.0 in stage 2.0 (TID 126)
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 127
20/11/16 15:31:19 INFO Executor: Running task 95.0 in stage 2.0 (TID 127)
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 128
20/11/16 15:31:19 INFO Executor: Running task 96.0 in stage 2.0 (TID 128)
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 124, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 92 (task 124, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO Executor: Finished task 92.0 in stage 2.0 (TID 124). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 129
20/11/16 15:31:19 INFO Executor: Running task 97.0 in stage 2.0 (TID 129)
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 128, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 96 (task 128, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 125, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 127, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 93 (task 125, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 95 (task 127, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 126, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO Executor: Finished task 96.0 in stage 2.0 (TID 128). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 94 (task 126, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO Executor: Finished task 93.0 in stage 2.0 (TID 125). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO Executor: Finished task 95.0 in stage 2.0 (TID 127). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO Executor: Finished task 94.0 in stage 2.0 (TID 126). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 130
20/11/16 15:31:19 INFO Executor: Running task 98.0 in stage 2.0 (TID 130)
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 131
20/11/16 15:31:19 INFO Executor: Running task 99.0 in stage 2.0 (TID 131)
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 132
20/11/16 15:31:19 INFO Executor: Running task 100.0 in stage 2.0 (TID 132)
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 133
20/11/16 15:31:19 INFO Executor: Running task 101.0 in stage 2.0 (TID 133)
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:19 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 129, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO DataWritingSparkTask: Committed partition 97 (task 129, attempt 0, stage 2.0)
20/11/16 15:31:19 INFO Executor: Finished task 97.0 in stage 2.0 (TID 129). 3491 bytes result sent to driver
20/11/16 15:31:19 INFO CoarseGrainedExecutorBackend: Got assigned task 134
20/11/16 15:31:19 INFO Executor: Running task 102.0 in stage 2.0 (TID 134)
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 131, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 99 (task 131, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 133, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 130, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 101 (task 133, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 132, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 98 (task 130, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 100 (task 132, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO Executor: Finished task 99.0 in stage 2.0 (TID 131). 3491 bytes result sent to driver
20/11/16 15:31:20 INFO Executor: Finished task 101.0 in stage 2.0 (TID 133). 3491 bytes result sent to driver
20/11/16 15:31:20 INFO Executor: Finished task 98.0 in stage 2.0 (TID 130). 3491 bytes result sent to driver
20/11/16 15:31:20 INFO Executor: Finished task 100.0 in stage 2.0 (TID 132). 3491 bytes result sent to driver
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 135
20/11/16 15:31:20 INFO Executor: Running task 103.0 in stage 2.0 (TID 135)
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 136
20/11/16 15:31:20 INFO Executor: Running task 104.0 in stage 2.0 (TID 136)
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 137
20/11/16 15:31:20 INFO Executor: Running task 105.0 in stage 2.0 (TID 137)
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 138
20/11/16 15:31:20 INFO Executor: Running task 106.0 in stage 2.0 (TID 138)
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 134, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 102 (task 134, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO Executor: Finished task 102.0 in stage 2.0 (TID 134). 3491 bytes result sent to driver
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 139
20/11/16 15:31:20 INFO Executor: Running task 107.0 in stage 2.0 (TID 139)
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 137, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 136, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 105 (task 137, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 135, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 138, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 103 (task 135, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 104 (task 136, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 106 (task 138, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO Executor: Finished task 105.0 in stage 2.0 (TID 137). 3491 bytes result sent to driver
20/11/16 15:31:20 INFO Executor: Finished task 103.0 in stage 2.0 (TID 135). 3491 bytes result sent to driver
20/11/16 15:31:20 INFO Executor: Finished task 106.0 in stage 2.0 (TID 138). 3491 bytes result sent to driver
20/11/16 15:31:20 INFO Executor: Finished task 104.0 in stage 2.0 (TID 136). 3491 bytes result sent to driver
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 140
20/11/16 15:31:20 INFO Executor: Running task 108.0 in stage 2.0 (TID 140)
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 141
20/11/16 15:31:20 INFO Executor: Running task 109.0 in stage 2.0 (TID 141)
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 142
20/11/16 15:31:20 INFO Executor: Running task 110.0 in stage 2.0 (TID 142)
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 143
20/11/16 15:31:20 INFO Executor: Running task 111.0 in stage 2.0 (TID 143)
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 139, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 107 (task 139, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO Executor: Finished task 107.0 in stage 2.0 (TID 139). 3491 bytes result sent to driver
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 144
20/11/16 15:31:20 INFO Executor: Running task 112.0 in stage 2.0 (TID 144)
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 143, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 111 (task 143, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 141, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 142, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 109 (task 141, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 140, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 110 (task 142, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 108 (task 140, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO Executor: Finished task 111.0 in stage 2.0 (TID 143). 3534 bytes result sent to driver
20/11/16 15:31:20 INFO Executor: Finished task 109.0 in stage 2.0 (TID 141). 3534 bytes result sent to driver
20/11/16 15:31:20 INFO Executor: Finished task 108.0 in stage 2.0 (TID 140). 3534 bytes result sent to driver
20/11/16 15:31:20 INFO Executor: Finished task 110.0 in stage 2.0 (TID 142). 3534 bytes result sent to driver
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 145
20/11/16 15:31:20 INFO Executor: Running task 113.0 in stage 2.0 (TID 145)
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 146
20/11/16 15:31:20 INFO Executor: Running task 114.0 in stage 2.0 (TID 146)
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 147
20/11/16 15:31:20 INFO Executor: Running task 115.0 in stage 2.0 (TID 147)
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 148
20/11/16 15:31:20 INFO Executor: Running task 116.0 in stage 2.0 (TID 148)
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:20 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 144, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO DataWritingSparkTask: Committed partition 112 (task 144, attempt 0, stage 2.0)
20/11/16 15:31:20 INFO Executor: Finished task 112.0 in stage 2.0 (TID 144). 3534 bytes result sent to driver
20/11/16 15:31:20 INFO CoarseGrainedExecutorBackend: Got assigned task 149
20/11/16 15:31:20 INFO Executor: Running task 117.0 in stage 2.0 (TID 149)
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 148, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 116 (task 148, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 147, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 145, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 115 (task 147, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 113 (task 145, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 146, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 114 (task 146, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO Executor: Finished task 116.0 in stage 2.0 (TID 148). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO Executor: Finished task 115.0 in stage 2.0 (TID 147). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO Executor: Finished task 113.0 in stage 2.0 (TID 145). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO Executor: Finished task 114.0 in stage 2.0 (TID 146). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 150
20/11/16 15:31:21 INFO Executor: Running task 118.0 in stage 2.0 (TID 150)
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 151
20/11/16 15:31:21 INFO Executor: Running task 119.0 in stage 2.0 (TID 151)
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 152
20/11/16 15:31:21 INFO Executor: Running task 120.0 in stage 2.0 (TID 152)
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 153
20/11/16 15:31:21 INFO Executor: Running task 121.0 in stage 2.0 (TID 153)
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 149, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 117 (task 149, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO Executor: Finished task 117.0 in stage 2.0 (TID 149). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 154
20/11/16 15:31:21 INFO Executor: Running task 122.0 in stage 2.0 (TID 154)
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 153, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 121 (task 153, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 151, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 152, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 119 (task 151, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 120 (task 152, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 150, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 118 (task 150, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO Executor: Finished task 121.0 in stage 2.0 (TID 153). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO Executor: Finished task 119.0 in stage 2.0 (TID 151). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO Executor: Finished task 120.0 in stage 2.0 (TID 152). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO Executor: Finished task 118.0 in stage 2.0 (TID 150). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 155
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 156
20/11/16 15:31:21 INFO Executor: Running task 123.0 in stage 2.0 (TID 155)
20/11/16 15:31:21 INFO Executor: Running task 124.0 in stage 2.0 (TID 156)
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 157
20/11/16 15:31:21 INFO Executor: Running task 125.0 in stage 2.0 (TID 157)
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 158
20/11/16 15:31:21 INFO Executor: Running task 126.0 in stage 2.0 (TID 158)
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 154, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 122 (task 154, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO Executor: Finished task 122.0 in stage 2.0 (TID 154). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 159
20/11/16 15:31:21 INFO Executor: Running task 127.0 in stage 2.0 (TID 159)
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 155, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 123 (task 155, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 156, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 157, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 158, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 124 (task 156, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 125 (task 157, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 126 (task 158, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO Executor: Finished task 123.0 in stage 2.0 (TID 155). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO Executor: Finished task 126.0 in stage 2.0 (TID 158). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO Executor: Finished task 124.0 in stage 2.0 (TID 156). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO Executor: Finished task 125.0 in stage 2.0 (TID 157). 3491 bytes result sent to driver
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 160
20/11/16 15:31:21 INFO Executor: Running task 128.0 in stage 2.0 (TID 160)
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 161
20/11/16 15:31:21 INFO Executor: Running task 129.0 in stage 2.0 (TID 161)
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 162
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO CoarseGrainedExecutorBackend: Got assigned task 163
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO Executor: Running task 130.0 in stage 2.0 (TID 162)
20/11/16 15:31:21 INFO Executor: Running task 131.0 in stage 2.0 (TID 163)
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:21 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 159, attempt 0, stage 2.0)
20/11/16 15:31:21 INFO DataWritingSparkTask: Committed partition 127 (task 159, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO Executor: Finished task 127.0 in stage 2.0 (TID 159). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 164
20/11/16 15:31:22 INFO Executor: Running task 132.0 in stage 2.0 (TID 164)
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 162, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 130 (task 162, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 163, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 131 (task 163, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 160, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 161, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 128 (task 160, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO Executor: Finished task 130.0 in stage 2.0 (TID 162). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 129 (task 161, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO Executor: Finished task 131.0 in stage 2.0 (TID 163). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO Executor: Finished task 128.0 in stage 2.0 (TID 160). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO Executor: Finished task 129.0 in stage 2.0 (TID 161). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 165
20/11/16 15:31:22 INFO Executor: Running task 133.0 in stage 2.0 (TID 165)
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 166
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 167
20/11/16 15:31:22 INFO Executor: Running task 134.0 in stage 2.0 (TID 166)
20/11/16 15:31:22 INFO Executor: Running task 135.0 in stage 2.0 (TID 167)
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 168
20/11/16 15:31:22 INFO Executor: Running task 136.0 in stage 2.0 (TID 168)
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 164, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 132 (task 164, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO Executor: Finished task 132.0 in stage 2.0 (TID 164). 3534 bytes result sent to driver
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 169
20/11/16 15:31:22 INFO Executor: Running task 137.0 in stage 2.0 (TID 169)
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 168, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 136 (task 168, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 167, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 135 (task 167, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 166, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 134 (task 166, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO Executor: Finished task 136.0 in stage 2.0 (TID 168). 3534 bytes result sent to driver
20/11/16 15:31:22 INFO Executor: Finished task 135.0 in stage 2.0 (TID 167). 3534 bytes result sent to driver
20/11/16 15:31:22 INFO Executor: Finished task 134.0 in stage 2.0 (TID 166). 3534 bytes result sent to driver
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 165, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 133 (task 165, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO Executor: Finished task 133.0 in stage 2.0 (TID 165). 3534 bytes result sent to driver
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 170
20/11/16 15:31:22 INFO Executor: Running task 138.0 in stage 2.0 (TID 170)
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 171
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 172
20/11/16 15:31:22 INFO Executor: Running task 140.0 in stage 2.0 (TID 172)
20/11/16 15:31:22 INFO Executor: Running task 139.0 in stage 2.0 (TID 171)
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 173
20/11/16 15:31:22 INFO Executor: Running task 141.0 in stage 2.0 (TID 173)
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 169, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 137 (task 169, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO Executor: Finished task 137.0 in stage 2.0 (TID 169). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 174
20/11/16 15:31:22 INFO Executor: Running task 142.0 in stage 2.0 (TID 174)
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 171, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 172, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 139 (task 171, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 170, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 140 (task 172, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 173, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 138 (task 170, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 141 (task 173, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO Executor: Finished task 139.0 in stage 2.0 (TID 171). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO Executor: Finished task 140.0 in stage 2.0 (TID 172). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO Executor: Finished task 138.0 in stage 2.0 (TID 170). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO Executor: Finished task 141.0 in stage 2.0 (TID 173). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 175
20/11/16 15:31:22 INFO Executor: Running task 143.0 in stage 2.0 (TID 175)
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 176
20/11/16 15:31:22 INFO Executor: Running task 144.0 in stage 2.0 (TID 176)
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 177
20/11/16 15:31:22 INFO Executor: Running task 145.0 in stage 2.0 (TID 177)
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 178
20/11/16 15:31:22 INFO Executor: Running task 146.0 in stage 2.0 (TID 178)
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:22 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 174, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO DataWritingSparkTask: Committed partition 142 (task 174, attempt 0, stage 2.0)
20/11/16 15:31:22 INFO Executor: Finished task 142.0 in stage 2.0 (TID 174). 3491 bytes result sent to driver
20/11/16 15:31:22 INFO CoarseGrainedExecutorBackend: Got assigned task 179
20/11/16 15:31:22 INFO Executor: Running task 147.0 in stage 2.0 (TID 179)
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 176, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 144 (task 176, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 177, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 145 (task 177, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 175, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO Executor: Finished task 144.0 in stage 2.0 (TID 176). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 143 (task 175, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 178, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 146 (task 178, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO Executor: Finished task 145.0 in stage 2.0 (TID 177). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO Executor: Finished task 143.0 in stage 2.0 (TID 175). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO Executor: Finished task 146.0 in stage 2.0 (TID 178). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 180
20/11/16 15:31:23 INFO Executor: Running task 150.0 in stage 2.0 (TID 180)
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 181
20/11/16 15:31:23 INFO Executor: Running task 151.0 in stage 2.0 (TID 181)
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 182
20/11/16 15:31:23 INFO Executor: Running task 152.0 in stage 2.0 (TID 182)
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 183
20/11/16 15:31:23 INFO Executor: Running task 153.0 in stage 2.0 (TID 183)
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 179, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 147 (task 179, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO Executor: Finished task 147.0 in stage 2.0 (TID 179). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 184
20/11/16 15:31:23 INFO Executor: Running task 154.0 in stage 2.0 (TID 184)
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 183, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 153 (task 183, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 181, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 182, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 180, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 151 (task 181, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 152 (task 182, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 150 (task 180, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO Executor: Finished task 153.0 in stage 2.0 (TID 183). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO Executor: Finished task 151.0 in stage 2.0 (TID 181). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO Executor: Finished task 150.0 in stage 2.0 (TID 180). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO Executor: Finished task 152.0 in stage 2.0 (TID 182). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 185
20/11/16 15:31:23 INFO Executor: Running task 155.0 in stage 2.0 (TID 185)
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 186
20/11/16 15:31:23 INFO Executor: Running task 156.0 in stage 2.0 (TID 186)
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 187
20/11/16 15:31:23 INFO Executor: Running task 157.0 in stage 2.0 (TID 187)
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 188
20/11/16 15:31:23 INFO Executor: Running task 158.0 in stage 2.0 (TID 188)
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 184, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 154 (task 184, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO Executor: Finished task 154.0 in stage 2.0 (TID 184). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 189
20/11/16 15:31:23 INFO Executor: Running task 159.0 in stage 2.0 (TID 189)
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 186, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 185, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 187, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 156 (task 186, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 155 (task 185, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 157 (task 187, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 188, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 158 (task 188, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO Executor: Finished task 157.0 in stage 2.0 (TID 187). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO Executor: Finished task 156.0 in stage 2.0 (TID 186). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO Executor: Finished task 155.0 in stage 2.0 (TID 185). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO Executor: Finished task 158.0 in stage 2.0 (TID 188). 3491 bytes result sent to driver
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 190
20/11/16 15:31:23 INFO Executor: Running task 160.0 in stage 2.0 (TID 190)
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 191
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 192
20/11/16 15:31:23 INFO Executor: Running task 161.0 in stage 2.0 (TID 191)
20/11/16 15:31:23 INFO Executor: Running task 162.0 in stage 2.0 (TID 192)
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 193
20/11/16 15:31:23 INFO Executor: Running task 163.0 in stage 2.0 (TID 193)
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:23 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 189, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO DataWritingSparkTask: Committed partition 159 (task 189, attempt 0, stage 2.0)
20/11/16 15:31:23 INFO Executor: Finished task 159.0 in stage 2.0 (TID 189). 3534 bytes result sent to driver
20/11/16 15:31:23 INFO CoarseGrainedExecutorBackend: Got assigned task 194
20/11/16 15:31:23 INFO Executor: Running task 164.0 in stage 2.0 (TID 194)
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 193, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 163 (task 193, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 190, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 191, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 160 (task 190, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 192, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 161 (task 191, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 162 (task 192, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO Executor: Finished task 163.0 in stage 2.0 (TID 193). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO Executor: Finished task 160.0 in stage 2.0 (TID 190). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO Executor: Finished task 162.0 in stage 2.0 (TID 192). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO Executor: Finished task 161.0 in stage 2.0 (TID 191). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 195
20/11/16 15:31:24 INFO Executor: Running task 165.0 in stage 2.0 (TID 195)
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 196
20/11/16 15:31:24 INFO Executor: Running task 166.0 in stage 2.0 (TID 196)
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 197
20/11/16 15:31:24 INFO Executor: Running task 167.0 in stage 2.0 (TID 197)
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 198
20/11/16 15:31:24 INFO Executor: Running task 168.0 in stage 2.0 (TID 198)
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 194, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 164 (task 194, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO Executor: Finished task 164.0 in stage 2.0 (TID 194). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 199
20/11/16 15:31:24 INFO Executor: Running task 169.0 in stage 2.0 (TID 199)
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 197, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 167 (task 197, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 195, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 198, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 196, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 165 (task 195, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 168 (task 198, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 166 (task 196, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO Executor: Finished task 167.0 in stage 2.0 (TID 197). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO Executor: Finished task 168.0 in stage 2.0 (TID 198). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO Executor: Finished task 165.0 in stage 2.0 (TID 195). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO Executor: Finished task 166.0 in stage 2.0 (TID 196). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 200
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 201
20/11/16 15:31:24 INFO Executor: Running task 171.0 in stage 2.0 (TID 200)
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 202
20/11/16 15:31:24 INFO Executor: Running task 173.0 in stage 2.0 (TID 202)
20/11/16 15:31:24 INFO Executor: Running task 172.0 in stage 2.0 (TID 201)
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 203
20/11/16 15:31:24 INFO Executor: Running task 174.0 in stage 2.0 (TID 203)
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 199, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 169 (task 199, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO Executor: Finished task 169.0 in stage 2.0 (TID 199). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 204
20/11/16 15:31:24 INFO Executor: Running task 175.0 in stage 2.0 (TID 204)
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 202, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 201, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 200, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 203, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 173 (task 202, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 172 (task 201, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 171 (task 200, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 174 (task 203, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO Executor: Finished task 171.0 in stage 2.0 (TID 200). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO Executor: Finished task 172.0 in stage 2.0 (TID 201). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO Executor: Finished task 174.0 in stage 2.0 (TID 203). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO Executor: Finished task 173.0 in stage 2.0 (TID 202). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 205
20/11/16 15:31:24 INFO Executor: Running task 176.0 in stage 2.0 (TID 205)
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 206
20/11/16 15:31:24 INFO Executor: Running task 177.0 in stage 2.0 (TID 206)
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 207
20/11/16 15:31:24 INFO Executor: Running task 178.0 in stage 2.0 (TID 207)
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 208
20/11/16 15:31:24 INFO Executor: Running task 179.0 in stage 2.0 (TID 208)
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 204, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 175 (task 204, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO Executor: Finished task 175.0 in stage 2.0 (TID 204). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 209
20/11/16 15:31:24 INFO Executor: Running task 180.0 in stage 2.0 (TID 209)
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 207, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 205, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 178 (task 207, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 176 (task 205, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO Executor: Finished task 176.0 in stage 2.0 (TID 205). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 208, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO Executor: Finished task 178.0 in stage 2.0 (TID 207). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 206, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 179 (task 208, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO DataWritingSparkTask: Committed partition 177 (task 206, attempt 0, stage 2.0)
20/11/16 15:31:24 INFO Executor: Finished task 179.0 in stage 2.0 (TID 208). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO Executor: Finished task 177.0 in stage 2.0 (TID 206). 3491 bytes result sent to driver
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 210
20/11/16 15:31:24 INFO Executor: Running task 181.0 in stage 2.0 (TID 210)
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 211
20/11/16 15:31:24 INFO Executor: Running task 182.0 in stage 2.0 (TID 211)
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 212
20/11/16 15:31:24 INFO CoarseGrainedExecutorBackend: Got assigned task 213
20/11/16 15:31:24 INFO Executor: Running task 184.0 in stage 2.0 (TID 213)
20/11/16 15:31:24 INFO Executor: Running task 183.0 in stage 2.0 (TID 212)
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 209, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 180 (task 209, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 180.0 in stage 2.0 (TID 209). 3491 bytes result sent to driver
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 214
20/11/16 15:31:25 INFO Executor: Running task 185.0 in stage 2.0 (TID 214)
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 211, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 182 (task 211, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 213, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 184 (task 213, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 210, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 212, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 182.0 in stage 2.0 (TID 211). 3534 bytes result sent to driver
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 181 (task 210, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 183 (task 212, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 184.0 in stage 2.0 (TID 213). 3534 bytes result sent to driver
20/11/16 15:31:25 INFO Executor: Finished task 183.0 in stage 2.0 (TID 212). 3534 bytes result sent to driver
20/11/16 15:31:25 INFO Executor: Finished task 181.0 in stage 2.0 (TID 210). 3534 bytes result sent to driver
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 215
20/11/16 15:31:25 INFO Executor: Running task 186.0 in stage 2.0 (TID 215)
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 216
20/11/16 15:31:25 INFO Executor: Running task 187.0 in stage 2.0 (TID 216)
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 217
20/11/16 15:31:25 INFO Executor: Running task 188.0 in stage 2.0 (TID 217)
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 218
20/11/16 15:31:25 INFO Executor: Running task 189.0 in stage 2.0 (TID 218)
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 214, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 185 (task 214, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 185.0 in stage 2.0 (TID 214). 3534 bytes result sent to driver
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 219
20/11/16 15:31:25 INFO Executor: Running task 190.0 in stage 2.0 (TID 219)
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 216, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 187 (task 216, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 187.0 in stage 2.0 (TID 216). 3491 bytes result sent to driver
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 215, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 217, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 186 (task 215, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 218, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 189 (task 218, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 186.0 in stage 2.0 (TID 215). 3491 bytes result sent to driver
20/11/16 15:31:25 INFO Executor: Finished task 189.0 in stage 2.0 (TID 218). 3491 bytes result sent to driver
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 188 (task 217, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 188.0 in stage 2.0 (TID 217). 3491 bytes result sent to driver
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 220
20/11/16 15:31:25 INFO Executor: Running task 191.0 in stage 2.0 (TID 220)
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 221
20/11/16 15:31:25 INFO Executor: Running task 192.0 in stage 2.0 (TID 221)
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 222
20/11/16 15:31:25 INFO Executor: Running task 193.0 in stage 2.0 (TID 222)
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 223
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO Executor: Running task 194.0 in stage 2.0 (TID 223)
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 219, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 190 (task 219, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 190.0 in stage 2.0 (TID 219). 3491 bytes result sent to driver
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 224
20/11/16 15:31:25 INFO Executor: Running task 195.0 in stage 2.0 (TID 224)
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 223, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 194 (task 223, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 194.0 in stage 2.0 (TID 223). 3491 bytes result sent to driver
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 221, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 192 (task 221, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 220, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 191 (task 220, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 191.0 in stage 2.0 (TID 220). 3491 bytes result sent to driver
20/11/16 15:31:25 INFO Executor: Finished task 192.0 in stage 2.0 (TID 221). 3491 bytes result sent to driver
20/11/16 15:31:25 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 222, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO DataWritingSparkTask: Committed partition 193 (task 222, attempt 0, stage 2.0)
20/11/16 15:31:25 INFO Executor: Finished task 193.0 in stage 2.0 (TID 222). 3491 bytes result sent to driver
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 225
20/11/16 15:31:25 INFO Executor: Running task 196.0 in stage 2.0 (TID 225)
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 226
20/11/16 15:31:25 INFO Executor: Running task 197.0 in stage 2.0 (TID 226)
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 227
20/11/16 15:31:25 INFO Executor: Running task 198.0 in stage 2.0 (TID 227)
20/11/16 15:31:25 INFO CoarseGrainedExecutorBackend: Got assigned task 228
20/11/16 15:31:25 INFO Executor: Running task 199.0 in stage 2.0 (TID 228)
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
20/11/16 15:31:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/11/16 15:31:26 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 224, attempt 0, stage 2.0)
20/11/16 15:31:26 INFO DataWritingSparkTask: Committed partition 195 (task 224, attempt 0, stage 2.0)
20/11/16 15:31:26 INFO Executor: Finished task 195.0 in stage 2.0 (TID 224). 3491 bytes result sent to driver
20/11/16 15:31:26 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 228, attempt 0, stage 2.0)
20/11/16 15:31:26 INFO DataWritingSparkTask: Committed partition 199 (task 228, attempt 0, stage 2.0)
20/11/16 15:31:26 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 226, attempt 0, stage 2.0)
20/11/16 15:31:26 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 225, attempt 0, stage 2.0)
20/11/16 15:31:26 INFO DataWritingSparkTask: Committed partition 197 (task 226, attempt 0, stage 2.0)
20/11/16 15:31:26 INFO DataWritingSparkTask: Committed partition 196 (task 225, attempt 0, stage 2.0)
20/11/16 15:31:26 INFO Executor: Finished task 199.0 in stage 2.0 (TID 228). 3491 bytes result sent to driver
20/11/16 15:31:26 INFO Executor: Finished task 197.0 in stage 2.0 (TID 226). 3491 bytes result sent to driver
20/11/16 15:31:26 INFO Executor: Finished task 196.0 in stage 2.0 (TID 225). 3491 bytes result sent to driver
20/11/16 15:31:26 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 227, attempt 0, stage 2.0)
20/11/16 15:31:26 INFO DataWritingSparkTask: Committed partition 198 (task 227, attempt 0, stage 2.0)
20/11/16 15:31:26 INFO Executor: Finished task 198.0 in stage 2.0 (TID 227). 3491 bytes result sent to driver
20/11/16 15:31:26 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/11/16 15:31:26 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
